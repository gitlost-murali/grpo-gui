"""
Generic image classification models and training utilities.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple, Dict
from torchvision.models import resnet50, ResNet50_Weights


class SimpleCNN(nn.Module):
    """
    Simple CNN model for image classification.
    """

    def __init__(self, num_classes: int):
        """
        Initialize the CNN model.

        Args:
            num_classes: Number of output classes
        """
        super(SimpleCNN, self).__init__()

        # Convolutional layers
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)

        # Pooling layer
        self.pool = nn.MaxPool2d(2, 2)

        # Fully connected layers
        self.fc1 = nn.Linear(128 * 28 * 28, 512)
        self.fc2 = nn.Linear(512, num_classes)

        # Dropout for regularization
        self.dropout = nn.Dropout(0.5)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass through the network.

        Args:
            x: Input tensor of shape (batch_size, 3, 224, 224)

        Returns:
            Output tensor of shape (batch_size, num_classes)
        """
        # Convolutional layers with ReLU and pooling
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))

        # Flatten the output
        x = x.view(-1, 128 * 28 * 28)

        # Fully connected layers with dropout
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)

        return x


def get_model(model_name: str, num_classes: int) -> nn.Module:
    """
    Get the specified model architecture.

    Args:
        model_name: Name of the model architecture ('simple_cnn' or 'resnet50')
        num_classes: Number of output classes

    Returns:
        PyTorch model
    """
    if model_name == "simple_cnn":
        return SimpleCNN(num_classes=num_classes)
    elif model_name == "resnet50":
        # Load pretrained ResNet50
        model = resnet50(weights=ResNet50_Weights.DEFAULT)

        # Replace the final fully connected layer
        num_features = model.fc.in_features
        model.fc = nn.Linear(num_features, num_classes)

        return model
    else:
        raise ValueError(
            f"Model '{model_name}' not supported. Available models: 'simple_cnn', 'resnet50'"
        )


def train_model(
    model: nn.Module,
    train_loader: torch.utils.data.DataLoader,
    test_loader: torch.utils.data.DataLoader,
    num_epochs: int = 10,
    learning_rate: float = 0.001,
    device: str = "cuda" if torch.cuda.is_available() else "cpu",
) -> Tuple[nn.Module, Dict[str, list]]:
    """
    Train an image classification model.

    Args:
        model: PyTorch model to train
        train_loader: DataLoader for training data
        test_loader: DataLoader for test data
        num_epochs: Number of training epochs
        learning_rate: Learning rate for optimizer
        device: Device to use for training ('cuda' or 'cpu')

    Returns:
        Tuple of (trained model, training history)
    """
    model = model.to(device)

    # Loss function and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    # Training history
    history = {"train_loss": [], "train_acc": [], "test_loss": [], "test_acc": []}

    # Training loop
    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Backward pass and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Statistics
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()

        # Calculate training metrics
        epoch_train_loss = train_loss / len(train_loader)
        epoch_train_acc = 100 * train_correct / train_total

        # Evaluation phase
        model.eval()
        test_loss = 0.0
        test_correct = 0
        test_total = 0

        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)

                # Forward pass
                outputs = model(images)
                loss = criterion(outputs, labels)

                # Statistics
                test_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                test_total += labels.size(0)
                test_correct += (predicted == labels).sum().item()

        # Calculate test metrics
        epoch_test_loss = test_loss / len(test_loader)
        epoch_test_acc = 100 * test_correct / test_total

        # Update history
        history["train_loss"].append(epoch_train_loss)
        history["train_acc"].append(epoch_train_acc)
        history["test_loss"].append(epoch_test_loss)
        history["test_acc"].append(epoch_test_acc)

        # Print progress
        print(
            f"Epoch [{epoch + 1}/{num_epochs}]: "
            f"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, "
            f"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.2f}%"
        )

    return model, history
